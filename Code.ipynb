{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1613d0ed-5633-4231-85bd-be5258b414de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion   # <-- add FeatureUnion here\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2c35d797-3f0d-45d2-bf47-1dea02a0b6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text   label\n",
      "0  DEbATinG IF BuRgERðŸ” Or bIRYanI is THe TRUe kIn...    food\n",
      "1  LATEst SMartpHONE bY opeNai dROPpEd tOdAy ðŸ”¥ wi...    tech\n",
      "2  cRicKet COMmeNTArY FelT bIasEd SmH BUT sTILL W...  sports\n",
      "3  sOfTwaRE upDatE HaD BuGZzZ again ðŸ˜‚ usErs on Tw...    tech\n",
      "4  soFTwarE updatE Had bugZzz AGAIN ðŸ˜‚ useRs On Tw...    tech\n",
      "Index(['text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file = '/Users/vijeethvj8/Downloads/Elevateme/TEXT_CLASSIFICATION/text classifcation.csv'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7d0aa30-96d4-439e-b160-2c0684b38e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "198abe1b-f1ef-4bbe-8146-3544ed6f6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.strip().str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6a16b54-d12f-402e-adf9-3018ee5907d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text   label\n",
      "0  Debating If BurgerðŸ” Or Biryani Is The True Kin...    food\n",
      "1  Latest Smartphone By Openai Dropped Today ðŸ”¥ Wi...    tech\n",
      "2  Cricket Commentary Felt Biased Smh But Still W...  sports\n",
      "3  Software Update Had Bugzzz Again ðŸ˜‚ Users On Tw...    tech\n",
      "4  Software Update Had Bugzzz Again ðŸ˜‚ Users On Tw...    tech\n",
      "label\n",
      "entertainment    2000\n",
      "food             2000\n",
      "politics         2000\n",
      "sports           2000\n",
      "tech             2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "category = df.groupby('label')['label'].value_counts()\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2db4c4d3-22ea-49c4-b534-aba3fcb7801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text   label  \\\n",
      "0  Debating If Burger Or Biryani Is The True King...    food   \n",
      "1  Latest Smartphone By Openai Dropped Today With...    tech   \n",
      "2  Cricket Commentary Felt Biased Smh But Still W...  sports   \n",
      "3  Software Update Had Bugzzz Again Users On Twit...    tech   \n",
      "4  Software Update Had Bugzzz Again Users On Twit...    tech   \n",
      "5  Tried The New Burger Yesterday Omg It Was Sooo...    food   \n",
      "6  Ronaldo Scored A Last Minute Goal Ppl Went Cra...  sports   \n",
      "7  Latest Smartphone By Apple Dropped Today With ...    tech   \n",
      "8  Debating If Burger Or Biryani Is The True King...    food   \n",
      "9  Cricket Commentary Felt Biased Smh But Still W...  sports   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0       Debating Burger Biryani True King Food Fight  \n",
      "1  Latest Smartphone Openai Dropped Today Ai Feat...  \n",
      "2  Cricket Commentary Felt Biased Smh Still Whatt...  \n",
      "3           Software Update Bugzzz Users Twitter Mad  \n",
      "4           Software Update Bugzzz Users Twitter Mad  \n",
      "5  Tried New Burger Yesterday Omg It Sooo Good Bi...  \n",
      "6  Ronaldo Scored Last Minute Goal Ppl Went Crazy...  \n",
      "7  Latest Smartphone Apple Dropped Today Ai Featu...  \n",
      "8       Debating Burger Biryani True King Food Fight  \n",
      "9  Cricket Commentary Felt Biased Smh Still Whatt...  \n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)\n",
    "df['text'] = df['text'].str.replace(r'  ', ' ', regex=True)\n",
    "stopping_words = [\n",
    "    # Articles\n",
    "    'A', 'An', 'The',\n",
    "    \n",
    "    # Pronouns\n",
    "    'I', 'We', 'You', 'He', 'She', 'They', 'Me', 'My', 'Mine', 'His', 'Her',\n",
    "    'Hers', 'Its', 'Your', 'Yours', 'Our', 'Ours', 'Their', 'Theirs', 'Them', 'Us',\n",
    "    \n",
    "    # Auxiliary verbs & modals\n",
    "    'Am', 'Is', 'Are', 'Was', 'Were', 'Be', 'Been', 'Being',\n",
    "    'Do', 'Does', 'Did', 'Doing',\n",
    "    'Have', 'Has', 'Had', 'Having',\n",
    "    'Will', 'Would', 'Shall', 'Should', 'Can', 'Could',\n",
    "    'May', 'Might', 'Must', 'Of',\n",
    "    \n",
    "    # Conjunctions\n",
    "    'And', 'But', 'Or', 'If', 'Because', 'While', 'Although', 'Though', 'Unless',\n",
    "    'Until', 'Than', 'Then',\n",
    "    \n",
    "    # Prepositions\n",
    "    'In', 'On', 'At', 'By', 'For', 'With', 'About', 'Against',\n",
    "    'Between', 'Into', 'Through', 'During', 'Before', 'After',\n",
    "    'Above', 'Below', 'From', 'Up', 'Down', 'Over', 'Under',\n",
    "    'Again', 'Further', 'Out', 'Off', 'Toward', 'Around',\n",
    "    \n",
    "    # Demonstratives\n",
    "    'This', 'That', 'These', 'Those',\n",
    "    \n",
    "    # Adverbs/Particles\n",
    "    'Not', 'No', 'Nor', 'So', 'Only', 'Very', 'Just', 'Even', 'Once'\n",
    "]\n",
    "\n",
    "\n",
    "# Create regex pattern for stopwords\n",
    "pattern = r'\\b(' + '|'.join(stopping_words) + r')\\b'\n",
    "\n",
    "# Remove stopwords\n",
    "df['cleaned_text'] = df['text'].str.replace(pattern, '', regex=True)\n",
    "\n",
    "# Remove extra spaces again\n",
    "df['cleaned_text'] = df['cleaned_text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "print(df.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df612e76-405d-4100-8c7c-742fade0356e",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------     1st Model     ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "525b1cea-8eaf-4f2a-8589-da9726722d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Model Comparison ==\n",
      "LogisticRegression | Acc: 1.0000 | Macro-F1: 1.0000\n",
      "LinearSVC        | Acc: 1.0000 | Macro-F1: 1.0000\n",
      "SGD_logistic     | Acc: 1.0000 | Macro-F1: 1.0000\n",
      "ComplementNB     | Acc: 1.0000 | Macro-F1: 1.0000\n",
      "MLP_shallow      | Acc: 1.0000 | Macro-F1: 1.0000\n",
      "\n",
      "== Best Model: LogisticRegression ==\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "entertainment       1.00      1.00      1.00       400\n",
      "         food       1.00      1.00      1.00       400\n",
      "     politics       1.00      1.00      1.00       400\n",
      "       sports       1.00      1.00      1.00       400\n",
      "         tech       1.00      1.00      1.00       400\n",
      "\n",
      "     accuracy                           1.00      2000\n",
      "    macro avg       1.00      1.00      1.00      2000\n",
      " weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "                entertainment  food  politics  sports  tech\n",
      "entertainment            400     0         0       0     0\n",
      "food                       0   400         0       0     0\n",
      "politics                   0     0       400       0     0\n",
      "sports                     0     0         0     400     0\n",
      "tech                       0     0         0       0   400\n"
     ]
    }
   ],
   "source": [
    "# 1) Train/Test split BEFORE any vectorizer fitting ---------------------------\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df['text'],\n",
    "    df['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "# 2) Vectorizers: word + char TF-IDF (robust to noisy/messy text) -------------\n",
    "# Note: We assume you already removed stopwords. If not, you can set stop_words='english'\n",
    "word_tfidf = TfidfVectorizer(\n",
    "    lowercase=True,           # normalize case\n",
    "    ngram_range=(1,2),        # unigrams + bigrams\n",
    "    max_features=30000,\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "char_tfidf = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(3,5),        # character 3-5grams help with typos/slang remnants\n",
    "    lowercase=True,\n",
    "    min_df=2,\n",
    "    max_features=30000\n",
    ")\n",
    "\n",
    "features = FeatureUnion([\n",
    "    ('word_tfidf', word_tfidf),\n",
    "    ('char_tfidf', char_tfidf)\n",
    "])\n",
    "\n",
    "# 3) Candidate models ----------------------------------------------------------\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000, n_jobs=None),\n",
    "    \"LinearSVC\": LinearSVC(),  # very strong baseline for text\n",
    "    \"SGD_logistic\": SGDClassifier(loss=\"log_loss\", max_iter=2000),  # fast, scalable\n",
    "    \"ComplementNB\": ComplementNB(),  # good for text with tf-idf\n",
    "    \"MLP_shallow\": MLPClassifier(hidden_layer_sizes=(256,), activation='relu', max_iter=50, random_state=42)\n",
    "}\n",
    "\n",
    "# 4) Evaluate each model with the same features pipeline -----------------------\n",
    "results = []\n",
    "predictions = {}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([\n",
    "        ('feat', features),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    pipe.fit(X_train_text, y_train)\n",
    "    y_pred = pipe.predict(X_test_text)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1m = f1_score(y_test, y_pred, average='macro')\n",
    "    results.append((name, acc, f1m))\n",
    "    predictions[name] = (pipe, y_pred)\n",
    "\n",
    "# Print summary\n",
    "print(\"== Model Comparison ==\")\n",
    "for name, acc, f1m in sorted(results, key=lambda x: x[2], reverse=True):\n",
    "    print(f\"{name:16s} | Acc: {acc:.4f} | Macro-F1: {f1m:.4f}\")\n",
    "\n",
    "# Show detailed report for the top model (by Macro-F1)\n",
    "best_name, _, _ = sorted(results, key=lambda x: x[2], reverse=True)[0]\n",
    "best_pipe, best_pred = predictions[best_name]\n",
    "print(\"\\n== Best Model:\", best_name, \"==\")\n",
    "print(classification_report(y_test, best_pred))\n",
    "\n",
    "# Optional: Confusion matrix for best model\n",
    "cm = confusion_matrix(y_test, best_pred, labels=sorted(df['label'].unique()))\n",
    "cm_df = pd.DataFrame(cm, index=sorted(df['label'].unique()), columns=sorted(df['label'].unique()))\n",
    "print(\"\\nConfusion Matrix (rows=true, cols=pred):\\n\", cm_df)\n",
    "\n",
    "# 5) OPTIONAL: Hyperparameter tuning for LR & LinearSVC ------------------------\n",
    "# (Run if your dataset size/time allows; comment out if not needed)\n",
    "param_grid_lr = {\n",
    "    'feat__word_tfidf__ngram_range': [(1,2)],\n",
    "    'feat__word_tfidf__min_df': [2,3,5],\n",
    "    'feat__char_tfidf__ngram_range': [(3,5)],\n",
    "    'clf__C': [0.5, 1.0, 2.0, 4.0]\n",
    "}\n",
    "param_grid_svc = {\n",
    "    'feat__word_tfidf__ngram_range': [(1,2)],\n",
    "    'feat__word_tfidf__min_df': [2,3,5],\n",
    "    'feat__char_tfidf__ngram_range': [(3,5)],\n",
    "    'clf__C': [0.5, 1.0, 2.0, 4.0]\n",
    "}\n",
    "\n",
    "def tune_and_report(clf, params, Xtr, ytr, Xte, yte, name):\n",
    "    pipe = Pipeline([('feat', features), ('clf', clf)])\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    gs = GridSearchCV(pipe, params, cv=cv, scoring='f1_macro', n_jobs=-1, verbose=0)\n",
    "    gs.fit(Xtr, ytr)\n",
    "    print(f\"\\n== GridSearch Best for {name} ==\")\n",
    "    print(\"Best params:\", gs.best_params_)\n",
    "    print(\"CV best f1_macro:\", gs.best_score_)\n",
    "    yhat = gs.predict(Xte)\n",
    "    print(\"Test Acc:\", accuracy_score(yte, yhat))\n",
    "    print(\"Test Macro-F1:\", f1_score(yte, yhat, average='macro'))\n",
    "    print(classification_report(yte, yhat))\n",
    "    return gs\n",
    "\n",
    "# Uncomment to run tuning (can take longer on large data)\n",
    "# best_lr = tune_and_report(LogisticRegression(max_iter=2000), param_grid_lr, X_train_text, y_train, X_test_text, y_test, \"LogReg\")\n",
    "# best_svc = tune_and_report(LinearSVC(), param_grid_svc, X_train_text, y_train, X_test_text, y_test, \"LinearSVC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d703f7e-e3f9-4c67-a6cf-85349d6237fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Brgr ðŸ” iz da best!!', 'food'), ('PM gave big speeech 2day', 'food'), ('Cric match woww ðŸ”¥ðŸ”¥', 'sports'), ('New AI phone dropped!', 'tech'), ('Oscars award show ðŸŽ¬', 'entertainment')]\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"Brgr ðŸ” iz da best!!\",     # should be food\n",
    "    \"PM gave big speeech 2day\", # politics\n",
    "    \"Cric match woww ðŸ”¥ðŸ”¥\",    # sports\n",
    "    \"New AI phone dropped!\",    # tech\n",
    "    \"Oscars award show ðŸŽ¬\"      # entertainment\n",
    "]\n",
    "preds = best_pipe.predict(test_sentences)\n",
    "print(list(zip(test_sentences, preds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13207d1-d3a9-4efa-9b2e-06e171854ad1",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------     2st Model     ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ccceeb6a-a84b-40cb-95cc-deab69712319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLEAN TEST ===\n",
      "Accuracy:  0.7549\n",
      "Macro-F1:  0.8245\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "entertainment       1.00      1.00      1.00       122\n",
      "         food       1.00      1.00      1.00       298\n",
      "     politics       1.00      1.00      1.00       510\n",
      "       sports       0.35      1.00      0.51       278\n",
      "         tech       1.00      0.44      0.61       930\n",
      "\n",
      "     accuracy                           0.75      2138\n",
      "    macro avg       0.87      0.89      0.82      2138\n",
      " weighted avg       0.92      0.75      0.77      2138\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "                     pred_entertainment  pred_food  pred_politics  pred_sports  \\\n",
      "true_entertainment                 122          0              0            0   \n",
      "true_food                            0        298              0            0   \n",
      "true_politics                        0          0            510            0   \n",
      "true_sports                          0          0              0          278   \n",
      "true_tech                            0          0              0          524   \n",
      "\n",
      "                    pred_tech  \n",
      "true_entertainment          0  \n",
      "true_food                   0  \n",
      "true_politics               0  \n",
      "true_sports                 0  \n",
      "true_tech                 406  \n",
      "\n",
      "=== NOISY ROBUSTNESS ===\n",
      "Robustness Accuracy (noisy probe): 0.7450\n",
      "\n",
      "Noisy sample predictions:\n",
      "- RAW: DEBaTE in PArlIAmEnT WaS NoISy Af lOL WIth truMP shOutinG again\n",
      "  NOISY: debate in was noisy af funny with shouting again\n",
      "  PRED: politics | TRUE: politics\n",
      "\n",
      "- RAW: tHE FOOTbaLL maTcH bETweEN manu aND reAL mADriD waS intEnsE wiTH Fans sHouting lOL ðŸ˜‚ðŸ”¥\n",
      "  NOISY: the football match manu and real madrid was intense with fans shouting funny ðŸ”¥\n",
      "  PRED: sports | TRUE: sports\n",
      "\n",
      "- RAW: LaTesT smArTPHone by OPENAI DroPped toDaY ðŸ”¥ With aI FeATurES but BaTTeRy suCkS lol\n",
      "  NOISY: latest smartphone by openai dropped 2day ðŸ”¥ with ai features but battery sucks\n",
      "  PRED: tech | TRUE: tech\n",
      "\n",
      "- RAW: ELEcTIOns rESuLts ShOwED CongreSS wINnIng bUt MAnY ppL SaID cORRUPTioN!!\n",
      "  NOISY: election results showed congress winning but many ppl said corruption\n",
      "  PRED: politics | TRUE: politics\n",
      "\n",
      "- RAW: Tried The NeW PaSTa YESterdAY OmG It wAS sooO GoOD ðŸ’¯ BUt a biT toO spiCy....\n",
      "  NOISY: tried the new omg it was soo good but a bit too spicy\n",
      "  PRED: food | TRUE: food\n",
      "\n",
      "Custom noisy predictions:\n",
      "- Brgr ðŸ” iz da best!! -> food\n",
      "- PM gave big speeech 2day -> politics\n",
      "- Cric match woww ðŸ”¥ðŸ”¥ -> sports\n",
      "- New AI phone dropped! -> tech\n",
      "- Oscars award show ðŸŽ¬ -> entertainment\n",
      "\n",
      "Saved: text_cls_stacked.joblib, confusion_matrix_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Text Classification â€“ Robust Classical Ensemble\n",
    "# =======================================\n",
    "import re, html, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load data and prep groups\n",
    "# -----------------------------\n",
    "df = pd.read_csv(file)[[\"text\", \"label\"]].dropna().drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Group \"fingerprint\" to avoid near-duplicate leakage in split\n",
    "def fingerprint(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\d+\", \" \", s)            # drop digits\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    # keep tokens longer than 3 chars to reduce noise\n",
    "    s = \" \".join([w for w in s.split() if len(w) > 3])\n",
    "    return s\n",
    "\n",
    "df[\"group\"] = df[\"text\"].map(fingerprint)\n",
    "\n",
    "# Group-wise split: 80% train / 20% test\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_idx, test_idx = next(gss.split(df[\"text\"], df[\"label\"], groups=df[\"group\"]))\n",
    "train_df = df.iloc[train_idx].copy()\n",
    "test_df  = df.iloc[test_idx].copy()\n",
    "\n",
    "# -------------------------------------\n",
    "# 2) Normalization + politics enrichment\n",
    "# -------------------------------------\n",
    "EMOJI_MAP = {\"ðŸ”\":\" burger \", \"ðŸ”¥\":\" fire \", \"ðŸŽ¬\":\" movie \"}\n",
    "SLANG = {\n",
    "    \"u\":\"you\",\"r\":\"are\",\"2day\":\"today\",\"tmrw\":\"tomorrow\",\"idk\":\"i dont know\",\n",
    "    \"lol\":\"funny\",\"smh\":\"disappointed\",\"pm\":\"prime minister\"\n",
    "}\n",
    "POLITICS_HINTS = {\n",
    "    r\"\\bparl(iament)?\\b\": \" parliament \",\n",
    "    r\"\\belection(s)?\\b\": \" election \",\n",
    "    r\"\\bminister\\b\": \" minister \",\n",
    "    r\"\\bspeech\\b\": \" speech \",\n",
    "}\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    s = html.unescape(str(s))\n",
    "    s = s.lower()\n",
    "    # collapse repeated characters: \"speeech\" -> \"speech\" (leave at most 2 in a row)\n",
    "    s = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", s)\n",
    "    # slang expansion\n",
    "    if SLANG:\n",
    "        s = re.sub(r\"\\b(\" + \"|\".join(map(re.escape, SLANG.keys())) + r\")\\b\",\n",
    "                   lambda m: SLANG[m.group(0)], s)\n",
    "    # emoji mapping\n",
    "    s = \"\".join(EMOJI_MAP.get(ch, ch) for ch in s)\n",
    "    # urls & non-alphanumeric cleanup\n",
    "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def enrich_politics(s: str) -> str:\n",
    "    for pat, rep in POLITICS_HINTS.items():\n",
    "        s = re.sub(pat, rep, s)\n",
    "    return s\n",
    "\n",
    "def normalize_plus(s: str) -> str:\n",
    "    return enrich_politics(normalize(s))\n",
    "\n",
    "train_df[\"norm\"] = train_df[\"text\"].map(normalize_plus)\n",
    "test_df[\"norm\"]  = test_df[\"text\"].map(normalize_plus)\n",
    "\n",
    "# -------------------------------------\n",
    "# 3) Features: word + char TF-IDF\n",
    "# -------------------------------------\n",
    "word_tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    max_features=30000,\n",
    "    min_df=2,\n",
    "    lowercase=True\n",
    ")\n",
    "char_tfidf = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3,5),\n",
    "    max_features=30000,\n",
    "    min_df=2,\n",
    "    lowercase=True\n",
    ")\n",
    "features = FeatureUnion([(\"word\", word_tfidf), (\"char\", char_tfidf)])\n",
    "\n",
    "# -------------------------------------\n",
    "# 4) Stacked ensemble (probabilistic)\n",
    "# -------------------------------------\n",
    "svc_cal = CalibratedClassifierCV(LinearSVC(), method=\"isotonic\", cv=3, n_jobs=None)\n",
    "nb      = ComplementNB()\n",
    "sgd     = SGDClassifier(loss=\"log_loss\", max_iter=2000, tol=1e-3, random_state=RANDOM_STATE)\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=[(\"svc\", svc_cal), (\"nb\", nb), (\"sgd\", sgd)],\n",
    "    final_estimator=LogisticRegression(max_iter=2000, n_jobs=None, random_state=RANDOM_STATE),\n",
    "    stack_method=\"predict_proba\",\n",
    "    passthrough=False,\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "pipe = Pipeline([(\"feat\", features), (\"clf\", stack)])\n",
    "\n",
    "# -------------------------------------\n",
    "# 5) Train\n",
    "# -------------------------------------\n",
    "X_train, y_train = train_df[\"norm\"], train_df[\"label\"]\n",
    "X_test,  y_test  = test_df[\"norm\"],  test_df[\"label\"]\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------------------\n",
    "# 6) Evaluate on CLEAN test\n",
    "# -------------------------------------\n",
    "y_pred = pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1m = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(\"=== CLEAN TEST ===\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Macro-F1:  {f1m:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "labels_sorted = sorted(df[\"label\"].unique())\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels_sorted)\n",
    "cm_df = pd.DataFrame(cm, index=[f\"true_{l}\" for l in labels_sorted], columns=[f\"pred_{l}\" for l in labels_sorted])\n",
    "print(\"\\nConfusion Matrix:\\n\", cm_df)\n",
    "\n",
    "# -------------------------------------\n",
    "# 7) Noisy robustness evaluation\n",
    "#    (augment test with synthetic noise)\n",
    "# -------------------------------------\n",
    "def add_noise(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    # a few noisy transforms\n",
    "    s = re.sub(r\"\\btoday\\b\", \"2day\", s)\n",
    "    s = re.sub(r\"\\bprime minister\\b\", \"pm\", s)\n",
    "    s = re.sub(r\"speech\", \"speeech\", s)\n",
    "    # sprinkle emoji keywords\n",
    "    s = s.replace(\"burger\", \"burger ðŸ”\").replace(\"movie\", \"movie ðŸŽ¬\").replace(\"fire\", \"ðŸ”¥\")\n",
    "    # random drop small words\n",
    "    words = s.split()\n",
    "    if len(words) > 5:\n",
    "        keep = [w for w in words if random.random() > 0.1]\n",
    "        s = \" \".join(keep) if keep else s\n",
    "    return s\n",
    "\n",
    "# Build a small noisy probe from test set\n",
    "probe = X_test.sample(min(200, len(X_test)), random_state=RANDOM_STATE)\n",
    "probe_noisy = probe.apply(add_noise)\n",
    "\n",
    "# Reuse normalize_plus at inference time (what model expects)\n",
    "probe_norm = probe_noisy.apply(normalize_plus)\n",
    "probe_pred = pipe.predict(probe_norm)\n",
    "robust_acc = (probe_pred == y_test.loc[probe.index]).mean()\n",
    "\n",
    "print(\"\\n=== NOISY ROBUSTNESS ===\")\n",
    "print(f\"Robustness Accuracy (noisy probe): {robust_acc:.4f}\")\n",
    "\n",
    "# Show a few noisy examples for the report\n",
    "print(\"\\nNoisy sample predictions:\")\n",
    "for i in probe.sample(5, random_state=RANDOM_STATE).index.tolist():\n",
    "    raw  = df.loc[i, \"text\"] if i in df.index else \"(sample)\"\n",
    "    nraw = probe_noisy.loc[i]\n",
    "    pred = pipe.predict([normalize_plus(nraw)])[0]\n",
    "    truth = y_test.loc[i]\n",
    "    print(f\"- RAW: {raw}\\n  NOISY: {nraw}\\n  PRED: {pred} | TRUE: {truth}\\n\")\n",
    "\n",
    "# Also your 5 custom noisy sentences\n",
    "custom_noisy = [\n",
    "    \"Brgr ðŸ” iz da best!!\",\n",
    "    \"PM gave big speeech 2day\",\n",
    "    \"Cric match woww ðŸ”¥ðŸ”¥\",\n",
    "    \"New AI phone dropped!\",\n",
    "    \"Oscars award show ðŸŽ¬\"\n",
    "]\n",
    "custom_pred = pipe.predict([normalize_plus(t) for t in custom_noisy])\n",
    "print(\"Custom noisy predictions:\")\n",
    "for t, p in zip(custom_noisy, custom_pred):\n",
    "    print(f\"- {t} -> {p}\")\n",
    "\n",
    "# -------------------------------------\n",
    "# 8) Save artifacts\n",
    "# -------------------------------------\n",
    "joblib.dump(pipe, \"text_cls_stacked.joblib\")\n",
    "cm_df.to_csv(\"confusion_matrix_clean.csv\", index=True)\n",
    "print(\"\\nSaved: text_cls_stacked.joblib, confusion_matrix_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985f183-0c7c-4cd1-98d9-9cd86a933a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "15b1fe4f-c55e-42d9-940b-4c1c12a5bcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 19:04:25.900 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.904 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.905 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.907 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.907 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.909 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.912 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.912 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.913 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.914 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.914 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.915 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.917 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.921 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.929 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.931 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.932 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.934 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.935 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.940 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.944 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.946 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.947 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.947 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.948 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.949 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.957 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.962 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.965 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.965 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:25.966 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.231 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.259 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.259 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.259 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.259 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.269 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.269 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.547 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.548 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.548 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.548 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.549 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.549 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-17 19:04:26.550 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b9db95-28cb-4f89-9c72-fa86c67f3e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
